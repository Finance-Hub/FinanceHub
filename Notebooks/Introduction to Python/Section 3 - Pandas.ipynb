{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "## Author: Gustavo Amarante\n",
    "\n",
    "Pandas is an open source library providing **high-performance, easy-to-use data structures and data analysis tools** for the Python programming language. The main idea behind this library is a **table**, which pandas calls a **`DataFrame`**. Pandas allows you to handle data in a way that is much more intuitive than other softwares, like MATLAB. Think of it as an Excel spreadsheet, which has named lines and columns. For those who used \"R\" before, pandas is to python as `dplyr` is to \"R\". Pandas also allows for very basic data visualization. \n",
    "\n",
    "The development of this library began in 2008 at [AQR Capital Management](https://www.aqr.com/). In 2009 the library was open sourced.\n",
    "\n",
    "If you are looking for a quick tutorial have a look at the [pandas cookbook](https://pandas.pydata.org/pandas-docs/stable/cookbook.html) or, if want to go deep in the details (and you should), here is the [official documentation](https://pandas.pydata.org/pandas-docs/stable/index.html). Scroll through the index and see what interests you (there is a friendly PDF version which has 2600 pages!!!).\n",
    "\n",
    "**Obs**: the name \"pandas\" comes from \"**Pan**el **Da**ta **S**tructure\", which was the original purpose of the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  # ignore this line for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# The `Series` Object\n",
    "You can think of a `Series` as a \"named sequence of indexed values\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clark    1968\n",
       "Bruce    1995\n",
       "Peter    1978\n",
       "Tony     1977\n",
       "Diana    1973\n",
       "Name: Birth Year, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by = pd.Series(index=['Clark', 'Bruce', 'Peter', 'Tony', 'Diana'], data=[1968, 1995, 1978, 1977, 1973], name='Birth Year')\n",
    "by   # We can make this code a little prettier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(by)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the values inside of the series by their index with different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1977"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by.loc['Tony']  # here 'loc' means 'location'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1968"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by.iloc[0]  # 'iloc' allows you to treat the series as a MATLAB object..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1973"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by.iloc[-1]  # ... but with a few different twists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, a pandas `Series` is holding a **single variable**. If we want to handle several variables at once, we need a different type of object..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# The `DataFrame` Object\n",
    "\n",
    "Think of a `DataFrame` as a collection of several `Series`.\n",
    "\n",
    "A `DataFrame` has three ingredients: `index` (observation identifier), `columns` (variable/`Series` identifier) and `data`.\n",
    "\n",
    "The cell below creates a `DataFrame` with two `Series`, the first one called \"Birth Year\" and the second one called \"Height\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Birth Year</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Clark</th>\n",
       "      <td>1968</td>\n",
       "      <td>1.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bruce</th>\n",
       "      <td>1995</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peter</th>\n",
       "      <td>1978</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tony</th>\n",
       "      <td>1977</td>\n",
       "      <td>1.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diana</th>\n",
       "      <td>1973</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Birth Year  Height\n",
       "Clark        1968    1.85\n",
       "Bruce        1995    1.65\n",
       "Peter        1978    1.75\n",
       "Tony         1977    1.69\n",
       "Diana        1973    1.64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df = pd.DataFrame(columns=['Birth Year', 'Height'], \n",
    "                     index=['Clark', 'Bruce', 'Peter', 'Tony', 'Diana'],\n",
    "                     data=[[1968, 1.85], \n",
    "                           [1995, 1.65], \n",
    "                           [1978, 1.75], \n",
    "                           [1977, 1.69], \n",
    "                           [1973, 1.64]])\n",
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(my_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other ways to declare a `DataFrame` that might be useful. For example, you can pass a `dict` variable to the `data` atribute, where the keys of the dictionary are the names of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Birth Year</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Clark</th>\n",
       "      <td>1968</td>\n",
       "      <td>1.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bruce</th>\n",
       "      <td>1995</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peter</th>\n",
       "      <td>1978</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tony</th>\n",
       "      <td>1977</td>\n",
       "      <td>1.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diana</th>\n",
       "      <td>1973</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Birth Year  Height\n",
       "Clark        1968    1.85\n",
       "Bruce        1995    1.65\n",
       "Peter        1978    1.75\n",
       "Tony         1977    1.69\n",
       "Diana        1973    1.64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = {'Birth Year': [1968, 1995, 1978, 1977, 1973],\n",
    "             'Height': [1.85, 1.65, 1.75, 1.69, 1.64]}\n",
    "\n",
    "index_list = ['Clark', 'Bruce', 'Peter', 'Tony', 'Diana']\n",
    "\n",
    "my_df = pd.DataFrame(data=data_dict, \n",
    "                     index=index_list)\n",
    "\n",
    "my_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our `DataFrame` we can access **variables** (columns/`Series`) using their column name or access the **observation** (line/index) using the `.loc[]` atribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clark    1.85\n",
       "Bruce    1.65\n",
       "Peter    1.75\n",
       "Tony     1.69\n",
       "Diana    1.64\n",
       "Name: Height, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df['Height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Birth Year    1973.00\n",
       "Height           1.64\n",
       "Name: Diana, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.loc['Diana']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A specific value can be acessed in three ways. Either by giving the column/index names or by explicitly giving the position on the dataframe using the `.iloc[]` atribute (Although you can access values by their positions, this is not considered good practice for programming)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df['Height']['Diana']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.loc['Diana', 'Height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.iloc[4, 1]  # Treats the DataFrame as a MATLAB matrix. It's not considered good practice, but it's possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the basics, lets work with a real data set.\n",
    "\n",
    "---\n",
    "\n",
    "# Reading Data From an Excel Spreadsheet\n",
    "On the example below we are going to use data from ENEM 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "enem_df = pd.read_excel(\"data/Planilhas_Enem_2015_download.xlsx\", skiprows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "What are the variables (columns) in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enem_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to look at the contents of the `DataFrame`, but not all it, use the `.head()`, `.tail()` or `.sample()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enem_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has a quick way to describe quantitative variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "enem_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the output of the `.describe()` method is also a `DataFrame`. Which means we access its values as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_query = enem_df.describe()\n",
    "my_query['MÉDIA ESCOLA']['max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "enem_df['MÉDIA ESCOLA']  #.hist()  # try \"bins\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selections / Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "enem_df['DEPENDÊNCIA ADMINISTRATIVA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "enem_df['DEPENDÊNCIA ADMINISTRATIVA'] == 'Privada'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_private = enem_df['DEPENDÊNCIA ADMINISTRATIVA'] == 'Privada'  # 'True' for private schools\n",
    "in_CE = enem_df['SIGLA DA UF'] == 'CE'  # 'True' for schools in CE\n",
    "enem_df[is_private & in_CE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can query based on partial matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "enem_df['NOME DA ENTIDADE'].str.contains('NOSSA SENHORA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name_filter = enem_df['NOME DA ENTIDADE'].str.contains('NOSSA SENHORA')\n",
    "enem_df[name_filter][['NOME DA ENTIDADE', 'MÉDIA ESCOLA', 'SIGLA DA UF']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining Commands\n",
    "***Question***: What are the five states with the highest average score? What are their abandon rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enem_df.groupby('SIGLA DA UF').mean()[['MÉDIA ESCOLA', 'TAXA DE ABANDONO']].sort_values('MÉDIA ESCOLA', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = enem_df.groupby('SIGLA DA UF').mean()[['MÉDIA ESCOLA']].sort_values('MÉDIA ESCOLA', ascending=False)\n",
    "result.plot()  # kind='bar', figsize=(15,6), ylim=[530, 585]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(enem_df['LOCALIZACAO'], enem_df['DEPENDÊNCIA ADMINISTRATIVA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(enem_df['LOCALIZACAO'], enem_df['DEPENDÊNCIA ADMINISTRATIVA'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(enem_df['LOCALIZACAO'], enem_df['DEPENDÊNCIA ADMINISTRATIVA'], margins=True, normalize='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot Tables\n",
    "This functionality works exactly as the pivot table from MS Excel or MS Access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(enem_df, values='MÉDIA ESCOLA', index='DEPENDÊNCIA ADMINISTRATIVA', columns='LOCALIZACAO', aggfunc=np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.pivot_table(enem_df, values='MÉDIA ESCOLA', index=['DEPENDÊNCIA ADMINISTRATIVA', 'LOCALIZACAO'], columns='SIGLA DA UF', aggfunc=np.mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Example - Fecth Data from the BCB\n",
    "If you find a good source of data and they happen to have a **data API**, it is very easy to build a function that fetches the data. In this example, we will make a wrapper for the [data API of the Time Series Management System](https://dadosabertos.bcb.gov.br/dataset/20542-saldo-da-carteira-de-credito-com-recursos-livres---total/resource/6e2b0c97-afab-4790-b8aa-b9542923cf88) ([Sistema de Gerenciamento de Séries](https://www3.bcb.gov.br/sgspub/localizarseries/localizarSeries.do?method=prepararTelaLocalizarSeries), SGS) of the brazilian central bank.\n",
    "\n",
    "The data is available in **JSON format** (google it!). The idea is to build a function that receives the Series ID and returns a DataFrame with the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_json('https://api.bcb.gov.br/dados/serie/bcdata.sgs.24364/dados?formato=json')\n",
    "df = df.set_index(pd.to_datetime(df['data'], dayfirst=True)).drop('data', axis='columns')\n",
    "df.columns = ['IBC-Br']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SGS_data(series_id, series_name):\n",
    "    url = f'https://api.bcb.gov.br/dados/serie/bcdata.sgs.{series_id}/dados?formato=json'\n",
    "    df = pd.read_json(url)\n",
    "    df = df.set_index(pd.to_datetime(df['data'], dayfirst=True)).drop('data', axis='columns')\n",
    "    df.columns = [series_name]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could make this function a bit more fancy by adding date filters, allowing to fecth several series at the same time (maybe by passing a list of series IDs). It would be perfect if you turned that into a python library so that everyone can use.\n",
    "\n",
    "To test our function, let's look at the IBC-Br with seasonal adjustment (Mohtly proxy for the brazilian GDP). Its series ID is 24364."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IBCbr = get_SGS_data(24364, 'IBC-Br')\n",
    "df_IBCbr.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pratical Example - Fetch Data from the FRED\n",
    "We can repeat the exercise but using the data API from the [FRED](https://fred.stlouisfed.org/). Their data API URL requires a bit more work to get a clean result, but thanks to python, its possible to do it in just a few lines. To fully understand the code below you will need to understand a bit more about regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFRED(ticker, series_name):\n",
    "    df = pd.read_csv('https://fred.stlouisfed.org/data/' + ticker + '.txt', sep='\\n')  # read data from website\n",
    "    series_start = df[df[df.columns[0]].str.contains('DATE\\s+VALUE')].index[0] + 1  # find the line where the series starts using regular expressions\n",
    "    df = df.loc[series_start:]  # drop header description\n",
    "    df = df[df.columns[0]].str.split('\\s+', expand=True)  # split strings between date and value\n",
    "    df = pd.DataFrame(data=df[1].values.astype(float), index=pd.to_datetime(df[0]), columns=[series_name])  # clean data\n",
    "    df.index.rename('Date', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test our scrapper, let's look at the american core CPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = getFRED('PAYEMS', 'payroll')  # CPILFESL  PAYEMS\n",
    "df[df.index > pd.to_datetime('2000-01-01')].diff(1).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling VS Rolling\n",
    "There is a difference between a moving average of the last 3 months and a series of quarterly frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['payroll change'] = df['payroll'].diff(1)\n",
    "df['payroll change 3m MA'] = df['payroll change'].rolling(3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[['payroll change', 'payroll change 3m MA']].plot(figsize=(15, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.resample()` method is different from the `.rolling()` because it changes the frequency of the series. All the resampling aliases are available [here](http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['payroll change'].resample('Q').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with financial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocks = pd.read_excel('data/stocks_portfolio.xlsx', sheet_name='Values')\n",
    "df_stocks.dropna(how='all')\n",
    "df_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocks.columns.str.slice(0, 5)\n",
    "# df_stocks.columns = df_stocks.columns.str.slice(0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocks.plot(figsize=(15,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_returns = df_stocks.pct_change(1)\n",
    "\n",
    "df_returns_1y = df_stocks.pct_change(252)\n",
    "df_returns_1y.plot(figsize=(15, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vols_1y = df_returns.rolling(252).aggregate(np.std)*np.sqrt(252)\n",
    "df_vols_1y.plot(figsize=(15, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_sharpe = df_returns_1y/df_vols_1y\n",
    "df_sharpe.plot(figsize=(15,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_returns.hist(figsize=(15,8), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_returns.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data From an SQL DataBase\n",
    "IF you have no idea of what SQL is, Google it!\n",
    "\n",
    "If you know what it is but do not know how to use it, there is a great [course from CodeCademy](https://www.codecademy.com/learn/learn-sql). It is a fast course, you can do everything in less than two hours.\n",
    "\n",
    "The example below is just to show that pandas is capable of grabing data straight from a database, without the need of specific software. The `.sqlite` file simulates an SQL Database. Usually you would put the address of the Database server in its place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "connection = sqlite3.connect('data/weather_2012.sqlite')\n",
    "query = 'SELECT * FROM weather_2012 WHERE temp > 0 LIMIT 10'\n",
    "DadosSQL = pd.read_sql(query, connection)\n",
    "DadosSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge and Concatenate\n",
    "[Here](https://pandas.pydata.org/pandas-docs/stable/merging.html) you can find a great tutorial with all the merging and concatenating possibilities. Pandas has the same \"set-theoritical join functionalities\" as an SQL database (outter join, inner join) and also some other time-series friendly methods.\n",
    "\n",
    "Here are a few examples. Lets create some example DataFrames e visualize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                    'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                    'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                    'D': ['D0', 'D1', 'D2', 'D3']},\n",
    "                    index=[0, 1, 2, 3])\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "                    'B': ['B4', 'B5', 'B6', 'B7'],\n",
    "                    'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "                    'D': ['D4', 'D5', 'D6', 'D7']},\n",
    "                     index=[4, 5, 6, 7])\n",
    "\n",
    "\n",
    "df3 = pd.DataFrame({'A': ['A8', 'A9', 'A10', 'A11'],\n",
    "                    'B': ['B8', 'B9', 'B10', 'B11'],\n",
    "                    'C': ['C8', 'C9', 'C10', 'C11'],\n",
    "                    'D': ['D8', 'D9', 'D10', 'D11']},\n",
    "                    index=[8, 9, 10, 11])\n",
    "\n",
    "\n",
    "df4 = pd.DataFrame({'B': ['B2', 'B3', 'B6', 'B7'],\n",
    "                    'D': ['D2', 'D3', 'D6', 'D7'],\n",
    "                    'F': ['F2', 'F3', 'F6', 'F7']},\n",
    "                   index=[2, 3, 6, 7])\n",
    "\n",
    "display(df1)\n",
    "display(df2)\n",
    "display(df3)\n",
    "display(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2, df3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df4], axis=0, join='outer', sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df4], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.append(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More elaborate merges are possible using the `merge` method. Details can be [found here](https://pandas.pydata.org/pandas-docs/stable/merging.html#database-style-dataframe-joining-merging)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
